{
  "description": "A pipeline of pipelines for Corelight log files. This pipeline is from the Github repository https://github.com/corelight/ecs-mapping. Please file all questions or issues with this configuration in the corresponding Github repository.",
  "version": 11221,
  "processors": [
    {
      "pipeline": {
        "name": "corelight_general_pipeline"
      }
    },
    {
      "set": {
        "description": "This field can be used to determine if a data type is a metric or not. Set all as 'no' first, then once it hits the specific call to the pipelines that handle metrics - it will be then be set to 'yes' This is a sort of tag. But tags are not good to use because of the drastic pipeline inefficiency of using a for in check.. so we create our own field and use an exact compare check",
        "field": "temporary_metadata_is_metric_log",
        "value": "no"
      }
    },
    {
      "set": {
        "description": "This field can be used to determine if a data type is a stats or not. Set all as 'no' first, then once it hits the specific call to the pipelines that handle stats - it will be then be set to 'yes' This is a sort of tag. But tags are not good to use because of the drastic pipeline inefficiency of using a for in check.. so we create our own field and use an exact compare check",
        "field": "temporary_metadata_is_stats_log",
        "value": "no"
      }
    },
    {
      "set": {
        "description": "This field can be used to determine if a data type is a netcontrol or not. Set all as 'no' first, then once it hits the specific call to the pipelines that handle stats - it will be then be set to 'yes' This is a sort of tag. But tags are not good to use because of the drastic pipeline inefficiency of using a for in check.. so we create our own field and use an exact compare check",
        "field": "temporary_metadata_is_netcontrol_log",
        "value": "no"
      }
    },
    {
      "set": {
        "description": "This field can be used to determine if a data type is a system type log or not. Set all as 'no' first, then once it hits the specific call to the pipelines that system logs - it will be then be set to 'yes' This is a sort of tag. But tags are not good to use because of the drastic pipeline inefficiency of using a for in check.. so we create our own field and use an exact compare check",
        "field": "temporary_metadata_is_system_log",
        "value": "no"
      }
    },
    {
      "set": {
        "description": "This field will be used to determine if a data type is a parse_failure or not for later on in index naming.",
        "field": "temporary_metadata_is_parse_failure",
        "value": "no"
      }
    },
    {
      "pipeline": {
        "description": "Logs that are system related.",
        "name": "corelight_system_related_info_general_pipeline",
        "if": "ctx.event?.dataset != null && [ 'audit', 'auditlog', 'broker', 'cluster', 'config', 'corelight_audit_log', 'corelight_license_capacity', 'loaded_scripts' ].contains(ctx.event?.dataset)"
      }
    },
    {
      "pipeline": {
        "description": "Logs that are metrics.",
        "name": "corelight_metrics_general_pipeline",
        "if": "ctx.event?.dataset != null && [ 'corelight_metrics_bro', 'corelight_metrics_cpu', 'corelight_metrics_disk', 'corelight_metrics_docker', 'corelight_metrics_iface', 'corelight_metrics_memory', 'corelight_metrics_s3', 'corelight_metrics_sftp', 'corelight_metrics_suricata', 'corelight_metrics_system', 'corelight_metrics_utilization', 'ml_metrics', 'corelight_ml_metrics' ].contains(ctx.event?.dataset)"
      }
    },
    {
      "pipeline": {
        "description": "Logs that are stats.",
        "name": "corelight_stats_general_pipeline",
        "if": "ctx.event?.dataset != null && [ 'capture_loss', 'conn_doctor', 'corelight_cloud_stats', 'corelight_overall_capture_loss', 'corelight_profiling', 'corelight_weird_stats', 'corelight_weird_stats', 'namecache', 'packet_filter', 'reporter', 'smartpcap-stats', 'stats', 'suricata_stats', 'weird_stats' ].contains(ctx.event?.dataset)"
      }
    },
    {
      "pipeline": {
        "description": "Logs that are netcontrol.",
        "name": "corelight_netcontrol_general_pipeline",
        "if": "ctx.event?.dataset != null && [ 'netcontrol', 'netcontrol_drop', 'netcontrol_shunt', 'openflow' ].contains(ctx.event?.dataset)"
      }
    },
    {
      "pipeline": {
        "description": "Log names that fit the pattern of 'corelight_*_log' are parsed by this pipeline.",
        "name": "corelight_{{{event.dataset}}}_pipeline",
        "ignore_missing_pipeline": true,
        "ignore_failure": false,
        "if": "ctx?.event?.dataset != null"
      }
    },
    {
      "pipeline": {
        "description": "If is a protocol log do extra enrichment and parsing. Protocol log AKA application or network protocol log.. ie: not a metric, stat, or other system log.",
        "if": "ctx.temporary_metadata_is_metric_log == 'no' && ctx.temporary_metadata_is_netcontrol_log == 'no' && ctx.temporary_metadata_is_stats_log == 'no' && ctx.temporary_metadata_is_system_log == 'no'",
        "name": "corelight_postprocess_metadata_logs_pipeline"
      }
    },
    {
      "pipeline": {
        "description": "Run pipeline that all logs need.",
        "name": "corelight_postprocess_all_pipeline"
      }
    }
  ],
  "on_failure" : [
    {
      "pipeline": {
        "description": "Run pipeline for handling ingest/parse failures (parse_failures).",
        "name": "corelight_postprocess_parse_failures_pipeline"
      }
    }
  ]
}
